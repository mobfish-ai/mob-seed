# Feature: LLM è¾…åŠ©åæ€

> çŠ¶æ€: archived
> å½’æ¡£æ—¥æœŸ: 2026-01-03
> ç‰ˆæœ¬: 1.0.0
> æŠ€æœ¯æ ˆ: JavaScript
> æ´¾ç”Ÿè·¯å¾„: skills/mob-seed/lib/ace/
> ä¼˜å…ˆçº§: Phase 4 (v3.1+)

## æ¦‚è¿° (Overview)

ä½¿ç”¨ LLM å¢å¼ºåæ€èƒ½åŠ›ï¼Œä»è§‚å¯Ÿä¸­æå–æ›´æ·±å±‚æ¬¡çš„æ´å¯Ÿå’Œæ¨¡å¼ã€‚

### ç›®æ ‡ç”¨æˆ·

- ä½¿ç”¨ mob-seed çš„å¼€å‘è€…
- éœ€è¦æ›´æ™ºèƒ½åˆ†æçš„é¡¹ç›®

### ä¸šåŠ¡çº¦æŸ

- LLM è°ƒç”¨ä¸ºå¯é€‰åŠŸèƒ½
- éœ€è¦é…ç½® API å¯†é’¥
- æœ¬åœ°/äº‘ç«¯æ¨¡å‹å¯é€‰
- ç”¨æˆ·ç¡®è®¤åæ‰é‡‡çº³å»ºè®®

---

## ADDED Requirements

### REQ-001: LLM æä¾›å•†æŠ½è±¡

The system SHALL support multiple LLM providers through abstraction.

**æä¾›å•†æ¥å£**:

```javascript
/**
 * LLM æä¾›å•†æ¥å£
 * @interface LLMProvider
 */
interface LLMProvider {
  /**
   * åˆ†æè§‚å¯Ÿå¹¶ç”Ÿæˆåæ€
   * @param {Observation[]} observations - è§‚å¯Ÿåˆ—è¡¨
   * @param {Object} context - é¡¹ç›®ä¸Šä¸‹æ–‡
   * @returns {Promise<ReflectionCandidate[]>}
   */
  analyzeObservations(observations, context);

  /**
   * ç”Ÿæˆææ¡ˆå»ºè®®
   * @param {Reflection} reflection - åæ€
   * @returns {Promise<ProposalSuggestion>}
   */
  suggestProposal(reflection);
}
```

**æ”¯æŒçš„æä¾›å•†**:

| æä¾›å•† | ç±»å‹ | é…ç½® |
|--------|------|------|
| OpenAI | äº‘ç«¯ | `ace.llm.provider: "openai"` |
| Anthropic | äº‘ç«¯ | `ace.llm.provider: "anthropic"` |
| Ollama | æœ¬åœ° | `ace.llm.provider: "ollama"` |
| Mock | æµ‹è¯• | `ace.llm.provider: "mock"` |

**Acceptance Criteria:**
- [x] AC-001: å®šä¹‰ LLMProvider æ¥å£
- [x] AC-002: å®ç° OpenAI é€‚é…å™¨
- [x] AC-003: å®ç° Anthropic é€‚é…å™¨
- [x] AC-004: å®ç° Ollama æœ¬åœ°é€‚é…å™¨
- [x] AC-005: æä¾› Mock é€‚é…å™¨ç”¨äºæµ‹è¯•

---

### REQ-002: é…ç½®æ”¯æŒ

The system SHALL support LLM configuration in config.json.

**é…ç½®ç»“æ„**:

```json
{
  "ace": {
    "llm": {
      "enabled": false,
      "provider": "openai",
      "model": "gpt-4o-mini",
      "api_key_env": "OPENAI_API_KEY",
      "options": {
        "temperature": 0.3,
        "max_tokens": 1000
      },
      "fallback": "rule-based"
    }
  }
}
```

**é…ç½®è¯´æ˜**:

| é…ç½®é¡¹ | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|------|--------|------|
| llm.enabled | boolean | false | æ˜¯å¦å¯ç”¨ LLM |
| llm.provider | string | "openai" | æä¾›å•†åç§° |
| llm.model | string | æä¾›å•†é»˜è®¤ | æ¨¡å‹åç§° |
| llm.api_key_env | string | - | API å¯†é’¥ç¯å¢ƒå˜é‡å |
| llm.fallback | string | "rule-based" | å¤±è´¥æ—¶å›é€€ç­–ç•¥ |

**Acceptance Criteria:**
- [x] AC-006: æ”¯æŒ LLM é…ç½®è¯»å–
- [x] AC-007: API å¯†é’¥ä»ç¯å¢ƒå˜é‡è¯»å–
- [x] AC-008: é…ç½®æ ¡éªŒï¼ˆå¿…å¡«é¡¹æ£€æŸ¥ï¼‰
- [x] AC-009: æä¾›åˆç†é»˜è®¤å€¼

---

### REQ-003: è§‚å¯Ÿåˆ†æå¢å¼º

The system SHALL use LLM to analyze observations when enabled.

**åˆ†ææµç¨‹**:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM å¢å¼ºåæ€æµç¨‹                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                         â”‚
â”‚  1. æ”¶é›† triaged è§‚å¯Ÿ                   â”‚
â”‚  2. æ„å»ºåˆ†ææç¤ºè¯                       â”‚
â”‚  3. è°ƒç”¨ LLM API                        â”‚
â”‚  4. è§£æ LLM å“åº”                       â”‚
â”‚  5. ä¸è§„åˆ™åŒ¹é…ç»“æœåˆå¹¶                   â”‚
â”‚  6. å»é‡å’Œæ’åº                          â”‚
â”‚  7. è¿”å›å€™é€‰åæ€                        â”‚
â”‚                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æç¤ºè¯æ¨¡æ¿**:

```markdown
## ä»»åŠ¡

åˆ†æä»¥ä¸‹è½¯ä»¶å¼€å‘è§‚å¯Ÿè®°å½•ï¼Œè¯†åˆ«æ½œåœ¨çš„ç³»ç»Ÿæ€§é—®é¢˜å’Œæ”¹è¿›æœºä¼šã€‚

## è§‚å¯Ÿåˆ—è¡¨

{{observations}}

## é¡¹ç›®ä¸Šä¸‹æ–‡

- é¡¹ç›®åç§°: {{project_name}}
- æŠ€æœ¯æ ˆ: {{tech_stack}}
- æ ¸å¿ƒè§„æ ¼: {{specs}}

## è¾“å‡ºæ ¼å¼

è¯·è¿”å› JSON æ ¼å¼çš„åæ€å»ºè®®:

```json
{
  "reflections": [
    {
      "pattern": "æ¨¡å¼åç§°",
      "confidence": 0.85,
      "lesson": "å‘ç°çš„æ•™è®­",
      "observations": ["obs-001", "obs-002"],
      "suggested_actions": ["è¡ŒåŠ¨1", "è¡ŒåŠ¨2"]
    }
  ]
}
```
```

**Acceptance Criteria:**
- [x] AC-010: å®ç°æç¤ºè¯æ¨¡æ¿
- [x] AC-011: æ”¯æŒä¸Šä¸‹æ–‡æ³¨å…¥
- [x] AC-012: è§£æ LLM JSON å“åº”
- [x] AC-013: å¤„ç†æ ¼å¼é”™è¯¯å“åº”
- [x] AC-014: ä¸è§„åˆ™åŒ¹é…ç»“æœåˆå¹¶

---

### REQ-004: å›é€€æœºåˆ¶

The system SHALL fallback to rule-based when LLM fails.

**å›é€€è§¦å‘æ¡ä»¶**:

| æ¡ä»¶ | å›é€€è¡Œä¸º |
|------|---------|
| LLM æœªé…ç½® | ç›´æ¥ä½¿ç”¨è§„åˆ™åŒ¹é… |
| API è°ƒç”¨å¤±è´¥ | ä½¿ç”¨è§„åˆ™åŒ¹é… + è­¦å‘Š |
| å“åº”è§£æå¤±è´¥ | ä½¿ç”¨è§„åˆ™åŒ¹é… + è­¦å‘Š |
| è¶…æ—¶ (30s) | ä½¿ç”¨è§„åˆ™åŒ¹é… + è­¦å‘Š |

**å›é€€æµç¨‹**:

```javascript
async function analyzeWithFallback(observations) {
  if (!config.ace.llm.enabled) {
    return ruleBasedAnalysis(observations);
  }

  try {
    const llmResult = await llmProvider.analyzeObservations(observations);
    return mergeResults(llmResult, ruleBasedAnalysis(observations));
  } catch (error) {
    console.warn(`LLM åˆ†æå¤±è´¥ï¼Œå›é€€åˆ°è§„åˆ™åŒ¹é…: ${error.message}`);
    return ruleBasedAnalysis(observations);
  }
}
```

**Acceptance Criteria:**
- [x] AC-015: LLM ç¦ç”¨æ—¶ä½¿ç”¨è§„åˆ™åŒ¹é…
- [x] AC-016: API å¤±è´¥æ—¶è‡ªåŠ¨å›é€€
- [x] AC-017: è®°å½•å›é€€åŸå› 
- [x] AC-018: å›é€€åç»§ç»­æ­£å¸¸æµç¨‹

---

### REQ-005: ç»“æœåˆå¹¶ç­–ç•¥

The system SHALL merge LLM and rule-based results intelligently.

**åˆå¹¶ç­–ç•¥**:

```javascript
function mergeResults(llmResults, ruleResults) {
  const merged = [];
  const seen = new Set();

  // 1. æ·»åŠ é«˜ç½®ä¿¡åº¦ LLM ç»“æœ
  for (const r of llmResults) {
    if (r.confidence >= 0.7) {
      merged.push({ ...r, source: 'llm' });
      seen.add(r.observations.sort().join(','));
    }
  }

  // 2. æ·»åŠ è§„åˆ™åŒ¹é…ç»“æœï¼ˆä¸é‡å¤ï¼‰
  for (const r of ruleResults) {
    const key = r.observations.sort().join(',');
    if (!seen.has(key)) {
      merged.push({ ...r, source: 'rule' });
    }
  }

  // 3. æŒ‰ç½®ä¿¡åº¦æ’åº
  return merged.sort((a, b) => b.confidence - a.confidence);
}
```

**åˆå¹¶è§„åˆ™**:
- LLM é«˜ç½®ä¿¡åº¦ (â‰¥0.7) ç»“æœä¼˜å…ˆ
- ç›¸åŒè§‚å¯Ÿé›†åˆçš„ç»“æœå»é‡
- ä¿ç•™æ¥æºæ ‡è®° (llm/rule)
- æŒ‰ç½®ä¿¡åº¦é™åºæ’åˆ—

**Acceptance Criteria:**
- [x] AC-019: å®ç°ç»“æœåˆå¹¶é€»è¾‘
- [x] AC-020: å»é™¤é‡å¤å€™é€‰
- [x] AC-021: ä¿ç•™æ¥æºæ ‡è®°
- [x] AC-022: æŒ‰ç½®ä¿¡åº¦æ’åº

---

### REQ-006: ç”¨æˆ·ç¡®è®¤å¢å¼º

The system SHALL show LLM source in reflection candidates.

**æ˜¾ç¤ºå¢å¼º**:

```
ğŸ’¡ å‘ç° 3 ä¸ªåæ€å»ºè®®

[1] ç±»å‹èšåˆ: test_failure (3 ä¸ªè§‚å¯Ÿ) [è§„åˆ™åŒ¹é…]
    ç½®ä¿¡åº¦: 85%
    æ•™è®­: é¡¹ç›®ç¼ºä¹ç»Ÿä¸€çš„ç©ºå€¼å¤„ç†ç­–ç•¥
    ...

[2] æ·±å±‚æ¨¡å¼: null ä¸ undefined æ··ç”¨ [LLM åˆ†æ] ğŸ¤–
    ç½®ä¿¡åº¦: 78%
    æ•™è®­: ä»£ç åº“ä¸­ null å’Œ undefined ä½¿ç”¨ä¸ä¸€è‡´ï¼Œ
          å»ºè®®ç»Ÿä¸€ä¸º null æˆ–é‡‡ç”¨ Optional æ¨¡å¼
    è§‚å¯Ÿ: obs-001, obs-002, obs-004
    æ“ä½œ: [a] æ¥å—  [r] æ‹’ç»  [s] è·³è¿‡  [d] è¯¦æƒ…
```

**è¯¦æƒ…è§†å›¾**:

```
[d] æŸ¥çœ‹ LLM åˆ†æè¯¦æƒ…

ğŸ“Š åˆ†æä¾æ®:
- è§‚å¯Ÿ obs-001: TypeError: undefined is not...
- è§‚å¯Ÿ obs-002: null check failed
- è§‚å¯Ÿ obs-004: Expected null, got undefined

ğŸ¤– LLM æ¨ç†:
"è¿™ä¸‰ä¸ªé”™è¯¯éƒ½æ¶‰åŠç©ºå€¼å¤„ç†ï¼Œä½†ä½¿ç”¨äº†ä¸åŒçš„ç©ºå€¼è¡¨ç¤ºã€‚
 obs-001 æœŸæœ›å€¼ä½†æ”¶åˆ° undefinedï¼Œobs-002 æ˜¾å¼æ£€æŸ¥ nullï¼Œ
 obs-004 è¡¨æ˜å­˜åœ¨ç±»å‹æ··æ·†ã€‚å»ºè®®åˆ¶å®šç»Ÿä¸€çš„ç©ºå€¼ç­–ç•¥ã€‚"

ğŸ“ å»ºè®®è¡ŒåŠ¨:
1. åœ¨ mission.md æ·»åŠ ç©ºå€¼å¤„ç†è§„èŒƒ
2. ä½¿ç”¨ ESLint è§„åˆ™å¼ºåˆ¶ä¸€è‡´æ€§
3. åˆ›å»º isNil() å·¥å…·å‡½æ•°ç»Ÿä¸€å¤„ç†
```

**Acceptance Criteria:**
- [x] AC-023: æ˜¾ç¤ºæ¥æºæ ‡è®° (è§„åˆ™/LLM)
- [x] AC-024: æ”¯æŒ [d] è¯¦æƒ…æŸ¥çœ‹
- [x] AC-025: æ˜¾ç¤º LLM æ¨ç†è¿‡ç¨‹
- [x] AC-026: æ˜¾ç¤ºå®Œæ•´å»ºè®®è¡ŒåŠ¨

---

### REQ-007: æˆæœ¬å’Œé™æµæ§åˆ¶

The system SHALL implement cost and rate limiting controls.

**æ§åˆ¶æªæ–½**:

```json
{
  "ace": {
    "llm": {
      "limits": {
        "max_observations_per_call": 10,
        "max_calls_per_day": 50,
        "min_interval_seconds": 60
      }
    }
  }
}
```

**é™æµé€»è¾‘**:

```javascript
class LLMRateLimiter {
  async checkLimit() {
    const today = new Date().toISOString().slice(0, 10);
    const usage = await this.getUsage(today);

    if (usage.calls >= this.config.max_calls_per_day) {
      throw new Error('å·²è¾¾åˆ°æ¯æ—¥è°ƒç”¨é™åˆ¶');
    }

    const lastCall = await this.getLastCallTime();
    const elapsed = Date.now() - lastCall;
    if (elapsed < this.config.min_interval_seconds * 1000) {
      const wait = this.config.min_interval_seconds - elapsed / 1000;
      throw new Error(`è¯·ç­‰å¾… ${wait.toFixed(0)} ç§’åé‡è¯•`);
    }
  }
}
```

**Acceptance Criteria:**
- [x] AC-027: é™åˆ¶æ¯æ¬¡è°ƒç”¨çš„è§‚å¯Ÿæ•°é‡
- [x] AC-028: é™åˆ¶æ¯æ—¥è°ƒç”¨æ¬¡æ•°
- [x] AC-029: å®ç°è°ƒç”¨é—´éš”æ§åˆ¶
- [x] AC-030: è¶…é™æ—¶ç»™å‡ºæ˜ç¡®æç¤º

---

## æ´¾ç”Ÿäº§ç‰© (Derived Outputs)

| ç±»å‹ | è·¯å¾„ | è¯´æ˜ |
|------|------|------|
| ä»£ç  | skills/mob-seed/lib/ace/llm-provider.js | LLM æä¾›å•†æ¥å£ |
| ä»£ç  | skills/mob-seed/lib/ace/providers/openai.js | OpenAI é€‚é…å™¨ |
| ä»£ç  | skills/mob-seed/lib/ace/providers/anthropic.js | Anthropic é€‚é…å™¨ |
| ä»£ç  | skills/mob-seed/lib/ace/providers/ollama.js | Ollama é€‚é…å™¨ |
| ä»£ç  | skills/mob-seed/lib/ace/llm-analyzer.js | LLM åˆ†æå™¨ |
| æµ‹è¯• | skills/mob-seed/test/ace/llm-analyzer.test.js | å•å…ƒæµ‹è¯• |

---

## ç›¸å…³è§„æ ¼

- proposal: openspec/changes/v3.0-ace-integration/proposal.md
- ä¾èµ–: pattern-matcher.fspec.md, reflect-handler.fspec.md
- è¢«ä¾èµ–: auto-propose.fspec.md
